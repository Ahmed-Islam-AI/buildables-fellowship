{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bf6da588",
      "metadata": {
        "id": "bf6da588"
      },
      "source": [
        "# **Buckle Up ! We are starting our week 2 roller coaster**\n",
        "\n",
        "In our first week we covered some theoritical concepts and completed our setup so its time we start building!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca6b55c5",
      "metadata": {
        "id": "ca6b55c5"
      },
      "source": [
        "## üìì**Conversational AI Concepts & Model Pipelines**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1b7ace2",
      "metadata": {
        "id": "f1b7ace2"
      },
      "source": [
        "üéØ By the end of this week, you will:\n",
        "\n",
        "- Understand LLMs, STT, TTS models and their roles.\n",
        "\n",
        "- Know how to connect to LLMs with APIs (Groq as example).\n",
        "\n",
        "- Use Python (requests + JSON) for API interaction.\n",
        "\n",
        "- Start building a basic chatbot with memory and preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e3c5144",
      "metadata": {
        "id": "8e3c5144"
      },
      "source": [
        "---\n",
        "\n",
        "## üåü Large Language Models (LLMs) üåü"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03968dc4",
      "metadata": {
        "id": "03968dc4"
      },
      "source": [
        "---\n",
        "\n",
        "### ‚ùó **Question 1**: What is an LLM?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dd894fc",
      "metadata": {
        "id": "9dd894fc"
      },
      "source": [
        "üëâ It‚Äôs like a super-smart text predictor that can read, understand, and generate human-like sentences.\n",
        "\n",
        "You give it some words ‚Üí it guesses the next words in a way that makes sense.\n",
        "\n",
        "For example:\n",
        "\n",
        "1) You ask a question ‚Üí it gives you an answer.\n",
        "\n",
        "2) You write a sentence ‚Üí it can complete it.\n",
        "\n",
        "3) You give it a topic ‚Üí it can write an essay, code, or even a story.\n",
        "\n",
        "So, its a type of AI trained on huge amounts of text data to generate or understand text.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77076ddc",
      "metadata": {
        "id": "77076ddc"
      },
      "source": [
        "### Types of LLMs\n",
        "\n",
        "1. Encoder-only models (e.g., BERT)\n",
        "\n",
        "    - Best for understanding text (classification, sentiment analysis, embeddings).\n",
        "\n",
        "    - ‚ùå Not good at generating text.\n",
        "\n",
        "2. Decoder-only models (e.g., GPT, LLaMA, Mistral)\n",
        "\n",
        "    - Best for text generation (chatbots, writing, summarization).\n",
        "\n",
        "    - What we use in chatbots.\n",
        "\n",
        "3. Encoder-decoder models (e.g., T5, BART)\n",
        "\n",
        "    - Good at transforming text (translation, summarization, Q&A)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "339099fe",
      "metadata": {
        "id": "339099fe"
      },
      "source": [
        "### Must-Knows about LLMs\n",
        "\n",
        "- They don‚Äôt ‚Äúthink‚Äù like humans ‚Üí They predict text based on training.\n",
        "\n",
        "- Garbage in ‚Üí garbage out: Poor prompts = poor answers.\n",
        "\n",
        "- Token limits: Models can only ‚Äúsee‚Äù a certain number of words at a time.\n",
        "\n",
        "- Biases: Trained on internet text ‚Üí may reflect biases/errors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b1b2dd4",
      "metadata": {
        "id": "8b1b2dd4"
      },
      "source": [
        "### üí° **Quick Questions**:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7753565a",
      "metadata": {
        "id": "7753565a"
      },
      "source": [
        "1. Why might a chatbot built on BERT (encoder-only) struggle to answer open-ended questions?\n",
        "\n",
        "- Answer üëâ BERT is mainly designed to understand text, not to generate it. So, while it‚Äôs good at finding meaning in sentences, it struggles to create long, open-ended answers like a conversation would need."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5feffca",
      "metadata": {
        "id": "a5feffca"
      },
      "source": [
        "---\n",
        "\n",
        "## üåü Speech-to-Text (STT) üåü"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9393abf7",
      "metadata": {
        "id": "9393abf7"
      },
      "source": [
        "---\n",
        "\n",
        "### ‚ùó **Question 2**: What is STT?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f54ac00",
      "metadata": {
        "id": "3f54ac00"
      },
      "source": [
        "üëâ listens to your voice and turns it into written text.\n",
        "\n",
        "- Converts **audio ‚Üí text**.\n",
        "- Enables voice input for conversational AI.\n",
        "- Think of it as the **ears** of the chatbot.\n",
        "\n",
        "**Popular STT Models**:\n",
        "\n",
        "1) **Whisper (OpenAI)** ‚Äì strong at multilingual speech recognition.\n",
        "2) **Google Speech-to-Text API** ‚Äì widely used, real-time transcription.\n",
        "3) **Vosk** ‚Äì lightweight, offline speech recognition.\n",
        "\n",
        "**Common Usages**\n",
        "\n",
        "1) Voice assistants (Alexa, Siri, Google Assistant).\n",
        "2) Automated captions in meetings or lectures.\n",
        "3) Voice-enabled customer support.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc99714c",
      "metadata": {
        "id": "cc99714c"
      },
      "source": [
        "### Must-Knows about STT\n",
        "\n",
        "- Accuracy depends on **noise, accents, clarity of speech**.\n",
        "\n",
        "- Some models need **internet connection** (API-based), others run **offline**.\n",
        "\n",
        "- Preprocessing audio (noise reduction) improves results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec23bf9a",
      "metadata": {
        "id": "ec23bf9a"
      },
      "source": [
        "### üí° **Quick Questions**:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "407d8a82",
      "metadata": {
        "id": "407d8a82"
      },
      "source": [
        "2. Why do you think meeting transcription apps like Zoom or Google Meet struggle when multiple people talk at once?\n",
        "\n",
        "- Answer üëâ Because the app can only clearly process one voice at a time. When people overlap, the software gets confused about whose words belong to which person."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2959a81",
      "metadata": {
        "id": "f2959a81"
      },
      "source": [
        "---\n",
        "\n",
        "## üåü Text-to-Speech (TTS) üåü"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6650b62d",
      "metadata": {
        "id": "6650b62d"
      },
      "source": [
        "---\n",
        "\n",
        "### ‚ùó **Question 3**: What is TTS?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjDKvf8oAgZB"
      },
      "source": [
        "üëâ takes written text and speaks it out loud in a human-like voice.\n",
        "\n",
        "- Converts **text ‚Üí audio (speech)**.\n",
        "- Think of it as the **mouth** of the chatbot.\n",
        "- Makes AI ‚Äúspeak‚Äù naturally.\n",
        "\n",
        "**Popular TTS Models**:\n",
        "\n",
        "1) **Google TTS** ‚Äì supports many languages and voices.\n",
        "2) **Amazon Polly** ‚Äì lifelike voice synthesis with customization.\n",
        "3) **ElevenLabs** ‚Äì cutting-edge, realistic voice cloning.\n",
        "\n",
        "**Common Usages**\n",
        "\n",
        "1) Screen readers for visually impaired users.\n",
        "2) AI chatbots with voice output.\n",
        "3) Audiobooks or podcast generation.\n",
        "\n",
        "---"
      ],
      "id": "NjDKvf8oAgZB"
    },
    {
      "cell_type": "markdown",
      "id": "cfdb2471",
      "metadata": {
        "id": "cfdb2471"
      },
      "source": [
        "### Must-Knows about TTS\n",
        "\n",
        "- Some voices sound robotic; others use **neural TTS** for natural tones.\n",
        "\n",
        "- Latency matters ‚Üí If too slow, conversation feels unnatural.\n",
        "\n",
        "- Some TTS services allow **custom voices**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee49cb51",
      "metadata": {
        "id": "ee49cb51"
      },
      "source": [
        "### üí° **Quick Questions**:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee8f3eb2",
      "metadata": {
        "id": "ee8f3eb2"
      },
      "source": [
        "3. If you were designing a voice-based AI tutor, what qualities would you want in its TTS voice (tone, speed, clarity, etc.)?\n",
        "\n",
        "- Answer üëâ The voice should sound clear, friendly, and natural. It should also speak at a comfortable speed so learners can easily follow along"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8042c582",
      "metadata": {
        "id": "8042c582"
      },
      "source": [
        "---\n",
        "\n",
        "## üåü Using APIs for LLMs with Groq üåü"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7889d8ee",
      "metadata": {
        "id": "7889d8ee",
        "outputId": "deeb779d-7621-486b-9981-05e1f492ae66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversational AI refers to the technology that enables computers or digital systems to simulate human-like conversations with humans. This is achieved through the use of natural language processing (NLP) and machine learning algorithms that allow AI systems to understand, interpret, and respond to human input in a way that feels natural and intuitive.\n",
            "\n",
            "Conversational AI can take many forms, including:\n",
            "\n",
            "1. **Chatbots**: These are AI-powered software programs that can engage in text-based conversations with humans, often used to provide customer support, answer frequently asked questions, or facilitate transactions.\n",
            "2. **Virtual assistants**: These are AI-powered digital assistants, such as Siri, Google Assistant, or Alexa, that can understand voice commands and respond with relevant information or actions.\n",
            "3. **Voice-controlled interfaces**: These are AI-powered interfaces that allow users to interact with devices using voice commands, such as smart speakers or home automation systems.\n",
            "4. **Live chat applications**: These are AI-powered chat platforms that allow humans to interact with companies or organizations in real-time, often used for customer support or sales purposes.\n",
            "\n",
            "The key characteristics of conversational AI include:\n",
            "\n",
            "1. **Natural language understanding**: The ability to comprehend human language and syntax.\n",
            "2. **Contextual understanding**: The ability to understand the context of the conversation and respond accordingly.\n",
            "3. **Sentiment analysis**: The ability to recognize and respond to emotions and tone.\n",
            "4. **Flexibility**: The ability to adapt to changing conversation flows and user inputs.\n",
            "\n",
            "Conversational AI has many applications, including:\n",
            "\n",
            "1. **Customer service**: AI-powered chatbots can provide 24/7 customer support and answer frequently asked questions.\n",
            "2. **Sales**: Conversational AI can be used to engage with customers, answer product inquiries, and facilitate transactions.\n",
            "3. **Healthcare**: Conversational AI can be used to provide patient support, answer medical questions, and facilitate health education.\n",
            "4. **Education**: Conversational AI can be used to provide personalized feedback, answer student questions, and facilitate learning.\n",
            "\n",
            "Overall, conversational AI has the potential to revolutionize the way we interact with technology and each other, making communication more natural, intuitive, and accessible.\n"
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key=\"\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello! What is conversational AI?\"}]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a56c20eb",
      "metadata": {
        "id": "a56c20eb"
      },
      "source": [
        "---\n",
        "\n",
        "## üåü Assignments üåü"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bcc2ce6",
      "metadata": {
        "id": "2bcc2ce6"
      },
      "source": [
        "### üìù Assignment 1: LLM Understanding\n",
        "\n",
        "* Write a short note (3‚Äì4 sentences) explaining the difference between **encoder-only, decoder-only, and encoder-decoder LLMs**.\n",
        "* Give one example usage of each.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "- An **encoder-only** model is mainly used to understand text. It reads sentences and finds meaning but cannot generate new text. e.g ***BERT*** is used for sentiment analysis.\n",
        "\n",
        "- A **decoder-only** model is mainly used to generate text. It predicts the next words and can write full answers, stories, or code but doesn‚Äôt focus on deep understanding. e.g **GPT** is used in chatbots.\n",
        "\n",
        "- An **encoder-decoder model** does both together. The encoder understands the input, and the decoder uses that understanding to produce new text, which makes it useful for tasks like translation and summarization. e.g **T5** is used in machine translation and summarization."
      ],
      "metadata": {
        "id": "BS59AP-MCEjb"
      },
      "id": "BS59AP-MCEjb"
    },
    {
      "cell_type": "markdown",
      "id": "370084b8",
      "metadata": {
        "id": "370084b8"
      },
      "source": [
        "### üìù Assignment 2: STT/TTS Exploration\n",
        "\n",
        "* Find **one STT model** and **one TTS model** (other than Whisper/Google).\n",
        "* Write down:\n",
        "\n",
        "  * What it does.\n",
        "  * One possible application."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Answer:***\n",
        "\n",
        "**STT Model ‚Äì Vosk**\n",
        "- It converts speech into text and works offline without needing the internet.\n",
        "- One application is creating real-time transcription apps for classrooms or meetings.\n",
        "\n",
        "**TTS Model ‚Äì Tacotron 2**\n",
        "- It converts written text into natural-sounding human speech.\n",
        "- One application is building voice assistants that can read messages aloud."
      ],
      "metadata": {
        "id": "d6P6mq2NEZlQ"
      },
      "id": "d6P6mq2NEZlQ"
    },
    {
      "cell_type": "markdown",
      "id": "84824b65",
      "metadata": {
        "id": "84824b65"
      },
      "source": [
        "### üìù Assignment 3: Build a Chatbot with Memory\n",
        "\n",
        "* Write a Python program that:\n",
        "\n",
        "  * Takes user input in a loop.\n",
        "  * Sends it to Groq API.\n",
        "  * Stores the last 5 messages in memory.\n",
        "  * Ends when user types `\"quit\"`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Replace with your actual API key\n",
        "API_KEY = \"your_groq_api_key\"\n",
        "API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "\n",
        "# To store last 5 messages\n",
        "memory = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    # Exit condition\n",
        "    if user_input.lower() == \"quit\":\n",
        "        print(\"Chatbot: Goodbye üëã\")\n",
        "        break\n",
        "\n",
        "    # Add user input to memory\n",
        "    memory.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Keep only last 5 messages\n",
        "    if len(memory) > 5:\n",
        "        memory = memory[-5:]\n",
        "\n",
        "    # Prepare API request\n",
        "    headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
        "    payload = {\n",
        "        \"model\": \"llama3-8b-8192\",   # example Groq model\n",
        "        \"messages\": memory\n",
        "    }\n",
        "\n",
        "    # Call Groq API\n",
        "    response = requests.post(API_URL, headers=headers, json=payload)\n",
        "    bot_reply = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "    # Print bot reply\n",
        "    print(\"Chatbot:\", bot_reply)\n",
        "\n",
        "    # Save bot reply in memory\n",
        "    memory.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
        "\n",
        "    # Keep only last 5 messages again\n",
        "    if len(memory) > 5:\n",
        "        memory = memory[-5:]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgjQoUZHHEkS",
        "outputId": "cb91ffeb-227f-42e1-e92d-364b05e1f86c"
      },
      "id": "bgjQoUZHHEkS",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: hi can you please tell me about the AI\n",
            "Chatbot: Artificial Intelligence (AI)!\n",
            "\n",
            "AI is a rapidly evolving field that involves creating machines that can perform tasks that typically require human intelligence, such as:\n",
            "\n",
            "1. **Learning**: AI systems can learn from data, adapt to new situations, and improve their performance over time.\n",
            "2. **Recognition**: AI can recognize patterns, images, speech, and text, and make decisions based on that recognition.\n",
            "3. **Reasoning**: AI systems can reason and draw conclusions based on given data and rules.\n",
            "\n",
            "There are many types of AI, including:\n",
            "\n",
            "1. **Machine Learning** (ML): AI that can learn from data without being explicitly programmed.\n",
            "2. **Deep Learning** (DL): A type of machine learning that uses neural networks to analyze data.\n",
            "3. **Natural Language Processing** (NLP): AI that can understand, generate, and process human language.\n",
            "4. **Robotics**: AI that controls robots and enables them to perform tasks.\n",
            "5. **Expert Systems**: AI that mimics human decision-making and knowledge.\n",
            "\n",
            "AI is used in many areas, such as:\n",
            "\n",
            "1. **Healthcare**: AI-powered diagnosis, treatment, and patient monitoring.\n",
            "2. **Finance**: AI-powered trading, risk analysis, and fraud detection.\n",
            "3. **Transportation**: AI-powered self-driving cars, traffic management, and route optimization.\n",
            "4. **Customer Service**: AI-powered chatbots and virtual assistants.\n",
            "5. **Cybersecurity**: AI-powered threat detection and response.\n",
            "\n",
            "Some examples of AI in action:\n",
            "\n",
            "1. **Virtual assistants**: Siri, Alexa, Google Assistant, and Cortana.\n",
            "2. **Self-driving cars**: Tesla, Waymo, and NVIDIA.\n",
            "3. **Image recognition**: Facebook's facial recognition, Google's image search.\n",
            "4. **Chatbots**: Customer service bots, language translation bots.\n",
            "5. **Recommendation systems**: Netflix, Amazon, and YouTube.\n",
            "\n",
            "As AI continues to evolve, we can expect to see many more exciting applications and innovations in various fields.\n",
            "\n",
            "Would you like to know more about a specific aspect of AI or its applications?\n",
            "You: how can i use it\n",
            "Chatbot: You can use AI in various ways, depending on your interests and goals. Here are some examples:\n",
            "\n",
            "1. **Develop your own AI projects**: You can use AI frameworks like TensorFlow, PyTorch, or Keras to build your own machine learning models. You can start with simple projects like image classification, speech recognition, or text analysis.\n",
            "2. **Use AI-powered tools**: Many AI-powered tools and applications are available for free or at a low cost. For example:\n",
            "\t* **Virtual assistants**: Use Alexa, Google Assistant, or Siri to control your smart home devices, set reminders, or answer questions.\n",
            "\t* **Image and video editors**: Use AI-powered tools like Adobe Fresco, Prisma, or Luminar to edit photos and videos.\n",
            "\t* **Chatbots**: Use Tars, ManyChat, or Dialogflow to create your own chatbots for customer service, marketing, or entertainment.\n",
            "3. **Learn from online courses and tutorials**: Websites like Coursera, edX, and Udemy offer courses on AI, machine learning, and data science. You can learn the basics of AI and build your own projects.\n",
            "4. **Use pre-trained AI models**: You can use pre-trained AI models like OpenAI's APIs, Google Cloud AI Platform, or Amazon SageMaker to build your own projects. These models are trained on large datasets and can perform tasks like image recognition, language translation, or sentiment analysis.\n",
            "5. **Participate in AI competitions and challenges**: Websites like Kaggle, Google AI Challenge, and Amazon Rekognition Challenge offer AI competitions and challenges. You can participate and learn from others while creating your own AI projects.\n",
            "\n",
            "Some popular AI applications and tools for beginners include:\n",
            "\n",
            "1. **Microsoft Azure Cognitive Services**: A suite of AI-powered tools for developers, including speech recognition, language translation, and image recognition.\n",
            "2. **Google Cloud AI Platform**: A suite of AI-powered tools for developers, including machine learning, natural language processing, and computer vision.\n",
            "3. **Apple Machine Learning**: A suite of AI-powered tools for developers, including machine learning, natural language processing, and computer vision.\n",
            "4. **TensorFlow**: An open-source AI framework for building and training machine learning models.\n",
            "5. **PyTorch**: An open-source AI framework for building and training machine learning models.\n",
            "\n",
            "Remember to always follow ethics and privacy guidelines when working with AI, and ensure that you have the necessary permissions and data to use certain AI technologies.\n",
            "\n",
            "Which AI application or tool would you like to learn more about?\n",
            "You: how can i use AI\n",
            "Chatbot: Here are some ways you can use AI:\n",
            "\n",
            "1. **Image and Video Analysis**: Use AI-powered tools like Google Cloud Vision, Amazon Rekognition, or Clarifai to analyze images and videos, and detect objects, faces, or sentiment.\n",
            "2. **Natural Language Processing**: Use AI-powered tools like Google Cloud Natural Language, Amazon Comprehend, or IBM Watson Natural Language Understanding to analyze text, detect sentiment, and understand language.\n",
            "3. **Chatbots and Virtual Assistants**: Use AI-powered tools like Dialogflow, ManyChat, or Tars to create chatbots and virtual assistants that can answer customer service questions, provide recommendations, and perform tasks.\n",
            "4. **Predictive Analytics**: Use AI-powered tools like Google Cloud Predictive Analytics, Azure Machine Learning, or Amazon SageMaker to build predictive models that can forecast sales, detect anomalies, and make recommendations.\n",
            "5. **Customer Service**: Use AI-powered tools like Freshdesk, Zendesk, or Salesforce Service Cloud to automate customer service, provide proactive support, and improve customer satisfaction.\n",
            "6. **Content Creation**: Use AI-powered tools like Adobe Fresco, Prisma, or Luminar to create AI-generated art, music, or videos.\n",
            "7. **Marketing and Advertising**: Use AI-powered tools like Google Ads, Facebook Ads, or Adobe Marketo to optimize ad targeting, personalize customer experiences, and measure campaign performance.\n",
            "8. **Healthcare**: Use AI-powered tools like IBM Watson Health, Philips Healthcare, or Medtronic to analyze medical images, diagnose diseases, and develop personalized treatment plans.\n",
            "9. **Education**: Use AI-powered tools like Coursera, edX, or Udemy to personalize learning experiences, track student progress, and provide adaptive feedback.\n",
            "10. **Home Automation**: Use AI-powered tools like Alexa, Google Home, or Siri to control smart home devices, schedule tasks, and receive notifications.\n",
            "\n",
            "Some popular AI platforms and tools include:\n",
            "\n",
            "1. **Google Cloud AI Platform**: A suite of AI-powered tools for developers, including machine learning, natural language processing, and computer vision.\n",
            "2. **Amazon SageMaker**: A fully managed service that provides machine learning capabilities for developers, including data preparation, model training, and deployment.\n",
            "3. **Microsoft Azure Machine Learning**: A suite of AI-powered tools for developers, including machine learning, natural language processing, and computer vision.\n",
            "4. **IBM Watson**: A cloud-based AI platform that provides machine learning, natural language processing, and computer vision capabilities.\n",
            "5. **TensorFlow**: An open-source AI framework for building and training machine learning models.\n",
            "6. **PyTorch**: An open-source AI framework for building and training machine learning models.\n",
            "\n",
            "These are just a few examples of how you can use AI. As AI continues to evolve, we can expect to see even more innovative applications across various industries.\n",
            "\n",
            "Which AI application or tool would you like to learn more about?\n",
            "You: quit\n",
            "Chatbot: Goodbye üëã\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aef3132",
      "metadata": {
        "id": "1aef3132"
      },
      "source": [
        "### üìù Assignment 4: Preprocessing Function\n",
        "\n",
        "* Write a function to clean user input:\n",
        "\n",
        "  * Lowercase text.\n",
        "  * Remove punctuation.\n",
        "  * Strip extra spaces.\n",
        "\n",
        "Test with: `\"  HELLo!!!  How ARE you?? \"`\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    # Remove extra spaces\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "# Test\n",
        "sample = \" HELLo!!! How ARE you?? \"\n",
        "print(\"Before:\", sample)\n",
        "print(\"After:\", clean_text(sample))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbMS7G-eKEnX",
        "outputId": "63405e0b-42d9-4956-8e26-2caaa4e9c9cd"
      },
      "id": "RbMS7G-eKEnX",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before:  HELLo!!! How ARE you?? \n",
            "After: hello how are you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53027998",
      "metadata": {
        "id": "53027998"
      },
      "source": [
        "### üìù Assignment 5: Text Preprocessing\n",
        "\n",
        "* Write a function that:\n",
        "\n",
        "    * Converts text to lowercase.\n",
        "    * Removes punctuation & numbers.\n",
        "    * Removes stopwords (`the, is, and...`).\n",
        "    * Applies stemming or lemmatization.\n",
        "    * Removes words shorter than 3 characters.\n",
        "    * Keeps only nouns, verbs, and adjectives (using POS tagging)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag, word_tokenize"
      ],
      "metadata": {
        "id": "wtzwv4QxKX0s"
      },
      "id": "wtzwv4QxKX0s",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary resources (run once)\n",
        "# Core downloads\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "\n",
        "# Taggers (new + legacy names, so it works in both environments)\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download(\"averaged_perceptron_tagger_eng\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOX8OGk4KY0Y",
        "outputId": "65c381c7-4f6d-48f7-fa35-aa354055abc5"
      },
      "id": "LOX8OGk4KY0Y",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text: str) -> str:\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation & numbers\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "\n",
        "    # Tokenize\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    words = [w for w in words if w not in stop_words]\n",
        "\n",
        "    # Lemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # POS tagging\n",
        "    pos_tags = pos_tag(words)\n",
        "\n",
        "    cleaned_words = []\n",
        "    for word, tag in pos_tags:\n",
        "        # Remove short words (<3 chars)\n",
        "        if len(word) < 3:\n",
        "            continue\n",
        "\n",
        "        # Keep only nouns, verbs, adjectives\n",
        "        if tag.startswith(\"N\"):\n",
        "            lemma = lemmatizer.lemmatize(word, \"n\")  # noun\n",
        "        elif tag.startswith(\"V\"):\n",
        "            lemma = lemmatizer.lemmatize(word, \"v\")  # verb\n",
        "        elif tag.startswith(\"J\"):\n",
        "            lemma = lemmatizer.lemmatize(word, \"a\")  # adjective\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        cleaned_words.append(lemma)\n",
        "\n",
        "    return \" \".join(cleaned_words)"
      ],
      "metadata": {
        "id": "aOb1tKZxKYxR"
      },
      "id": "aOb1tKZxKYxR",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \"The quick brown foxes are jumping quickly over the lazy dogs 123!!!\"\n",
        "print(\"Before:\", sample)\n",
        "print(\"After:\", preprocess_text(sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atRk2DKLKYrf",
        "outputId": "be3e0d1e-6d98-422c-e9f7-bda5af76714d"
      },
      "id": "atRk2DKLKYrf",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: The quick brown foxes are jumping quickly over the lazy dogs 123!!!\n",
            "After: quick brown fox jump lazy dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Second Method"
      ],
      "metadata": {
        "id": "Jhda8ki3PKwp"
      },
      "id": "Jhda8ki3PKwp"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQbZiOIoONET",
        "outputId": "81516545-74b0-4e7a-daf1-8ba129b4927e"
      },
      "id": "uQbZiOIoONET",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.16.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load small English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def preprocess_text_spacy(text: str) -> str:\n",
        "    doc = nlp(text.lower())\n",
        "\n",
        "    cleaned = []\n",
        "    for token in doc:\n",
        "        # Skip stopwords, punctuation, numbers, short words\n",
        "        if token.is_stop or token.is_punct or token.is_digit or len(token.text) < 3:\n",
        "            continue\n",
        "\n",
        "        # Keep only nouns, verbs, adjectives\n",
        "        if token.pos_ in [\"NOUN\", \"VERB\", \"ADJ\"]:\n",
        "            cleaned.append(token.lemma_)  # Lemmatized form\n",
        "\n",
        "    return \" \".join(cleaned)\n",
        "\n",
        "# Test\n",
        "sample = \"The quick brown foxes are jumping quickly over the lazy dogs 123!!!\"\n",
        "print(\"Before:\", sample)\n",
        "print(\"After:\", preprocess_text_spacy(sample))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ixyw4d33Ohig",
        "outputId": "e96839de-31f2-4046-d438-ba630c764a6c"
      },
      "id": "Ixyw4d33Ohig",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: The quick brown foxes are jumping quickly over the lazy dogs 123!!!\n",
            "After: quick brown fox jump lazy dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb68c035",
      "metadata": {
        "id": "bb68c035"
      },
      "source": [
        "### üìù Assignment 6: Reflection\n",
        "\n",
        "* Answer in 2‚Äì3 sentences:\n",
        "\n",
        "    * Why is context memory important in chatbots?\n",
        "    * Why should beginners always check **API limits and pricing**?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**\n",
        "\n",
        "**Context memory** is important in chatbots because it helps them remember previous parts of the conversation, making replies more natural and relevant instead of starting fresh every time.\n",
        "\n",
        "Beginners should always check **API limits** and pricing to avoid unexpected costs and to design their applications within the allowed usage, ensuring smooth and affordable development."
      ],
      "metadata": {
        "id": "jwt8XBQwr4DZ"
      },
      "id": "jwt8XBQwr4DZ"
    },
    {
      "cell_type": "markdown",
      "id": "4b787de4",
      "metadata": {
        "id": "4b787de4"
      },
      "source": [
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}